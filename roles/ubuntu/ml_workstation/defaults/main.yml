---
# Ubuntu ML Workstation Role Defaults
# Ubuntu-specific settings for ML training servers

# NVIDIA/CUDA Configuration
nvidia_config:
  install_drivers: true
  install_cuda: true
  install_cudnn: true
  cuda_version: "12.1"  # Compatible with PyTorch 2.0+
  driver_version: "latest"

# System optimization for ML workloads
ubuntu_ml_optimization:
  increase_shared_memory: true
  optimize_swap: true
  increase_file_limits: true
  install_build_essentials: true
  enable_performance_governor: true

# ML Development packages
ubuntu_ml_packages:
  system_packages:
    - build-essential
    - cmake
    - pkg-config
    - libjpeg-dev
    - libtiff5-dev
    - libpng-dev
    - libavcodec-dev
    - libavformat-dev
    - libswscale-dev
    - libv4l-dev
    - libxvidcore-dev
    - libx264-dev
    - libgtk-3-dev
    - libatlas-base-dev
    - gfortran
    - python3-dev
    - libhdf5-dev
    - libssl-dev
    - libffi-dev
    - libbz2-dev
    - libreadline-dev
    - libsqlite3-dev
    - libncursesw5-dev
    - libgdbm-dev
    - liblzma-dev
    - tk-dev
    - uuid-dev
  
  monitoring_packages:
    - htop
    - iotop
    - nvidia-ml-py3
    - gpustat
    - screen
    - tmux

# Docker configuration for ML
docker_ml_config:
  install_nvidia_runtime: true
  enable_gpu_support: true
  create_ml_networks: true

# Training server configuration
training_server:
  enable_jupyter: true
  jupyter_port: 8888
  enable_tensorboard: true  
  tensorboard_port: 6006
  enable_ssh_tunnel: true
  setup_screen_sessions: true

# Remote access and monitoring
remote_access:
  enable_vnc: false  # Only if GUI needed
  setup_reverse_tunnel: false
  monitoring_dashboard: true

# Data management
data_management:
  create_datasets_dir: true
  setup_nfs_mount: false
  optimize_io: true
  datasets_path: "/data/ml-datasets"