---
# CUDA 12.6 Installation - Complete NVIDIA stack with nvidia-driver-570-server
# Follows official NVIDIA CUDA installation guide
# Phase 1: Hardware detection and verification
# Phase 2: NVIDIA drivers installation
# Phase 3: CUDA 12.6 toolkit installation
# Phase 4: Environment configuration and verification

- name: Display CUDA 12.6 installation information
  ansible.builtin.debug:
    msg:
      - "Installing complete NVIDIA CUDA 12.6 stack with nvidia-driver-570-server for oaSentinel ML training"
      - "Hardware detection -> NVIDIA drivers -> CUDA toolkit -> Environment setup"
      - "PyTorch 2.5+ compatibility ensured"
      - "Current tags: {{ ansible_run_tags | default('no-tags') }}"
      - "Platform: {{ target_platform | default(ansible_distribution) }}"
  tags: [gpu, nvidia, cuda, info]

# Phase 1: Hardware Detection and Verification
- name: Check for NVIDIA hardware
  ansible.builtin.shell: |
    set -o pipefail
    lspci | grep -i nvidia || echo "NO_NVIDIA_HARDWARE"
  register: nvidia_hardware_check
  changed_when: false
  failed_when: false
  args:
    executable: /bin/bash
  tags: [gpu, nvidia, hardware]

- name: Display hardware detection results
  ansible.builtin.debug:
    msg: |
      NVIDIA Hardware Detection:
      {{ nvidia_hardware_check.stdout_lines | join('\n') if nvidia_hardware_check.stdout_lines else 'No NVIDIA hardware detected' }}
  tags: [gpu, nvidia, hardware, info]

- name: Fail if no NVIDIA hardware detected
  ansible.builtin.fail:
    msg: |
      No NVIDIA hardware detected on this system.
      CUDA installation requires compatible NVIDIA GPU hardware.
      Hardware check output: {{ nvidia_hardware_check.stdout }}
  when:
    - nvidia_hardware_check.stdout.find('NO_NVIDIA_HARDWARE') != -1
    - not (ignore_missing_gpu | default(false))
  tags: [gpu, nvidia, hardware]

- name: Check current NVIDIA driver status
  ansible.builtin.shell: nvidia-smi --query-gpu=name,driver_version --format=csv,noheader || echo "NO_DRIVER"
  register: current_nvidia_status
  changed_when: false
  failed_when: false
  tags: [gpu, nvidia, drivers, diagnosis]

- name: Set driver installation needed flag
  ansible.builtin.set_fact:
    driver_installation_needed: "{{ current_nvidia_status.stdout == 'NO_DRIVER' or 'Driver/library version mismatch' in current_nvidia_status.stdout or 'NVIDIA-SMI
      has failed' in current_nvidia_status.stdout }}"
  tags: [gpu, nvidia, drivers]

- name: Check current CUDA installation status
  ansible.builtin.shell: |
    set -o pipefail
    if [ -f "/usr/local/cuda/bin/nvcc" ]; then
      /usr/local/cuda/bin/nvcc --version | grep "release"
    elif [ -f "/usr/local/cuda-12.8/bin/nvcc" ]; then
      /usr/local/cuda-12.8/bin/nvcc --version | grep "release"
    else
      echo "NO_CUDA_FOUND"
    fi
  register: current_cuda_status
  changed_when: false
  failed_when: false
  args:
    executable: /bin/bash
  tags: [gpu, nvidia, cuda, diagnosis]

- name: Display current installation status
  ansible.builtin.debug:
    msg:
      - "Current NVIDIA Status:"
      - "  Driver: {{ current_nvidia_status.stdout if current_nvidia_status.stdout != 'NO_DRIVER' else 'Not installed' }}"
      - "  CUDA: {{ current_cuda_status.stdout if current_cuda_status.stdout != 'NO_CUDA_FOUND' else 'Not installed' }}"
      - "Proceeding with installation..."
  tags: [gpu, nvidia, info]

# Phase 2: Repository Setup and Driver Installation
- name: Remove conflicting nouveau driver
  community.general.modprobe:
    name: nouveau
    state: absent
  become: true
  failed_when: false
  tags: [gpu, nvidia, drivers]

- name: Blacklist nouveau driver permanently
  ansible.builtin.blockinfile:
    path: /etc/modprobe.d/blacklist-nouveau.conf
    marker: "# {mark} ANSIBLE MANAGED - Blacklist nouveau for CUDA"
    block: |
      blacklist nouveau
      options nouveau modeset=0
    create: true
    mode: "0644"
  become: true
  tags: [gpu, nvidia, drivers]

- name: Download CUDA keyring (Ubuntu 22.04)
  ansible.builtin.get_url:
    url: "https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb"
    dest: "/tmp/cuda-keyring_1.1-1_all.deb"
    mode: "0644"
  become: true
  tags: [gpu, nvidia, cuda, repo]

- name: Install CUDA repository keyring
  ansible.builtin.apt:
    deb: "/tmp/cuda-keyring_1.1-1_all.deb"
    state: present
  become: true
  tags: [gpu, nvidia, cuda, repo]

- name: Update apt cache after adding CUDA repository
  ansible.builtin.apt:
    update_cache: true
  become: true
  tags: [gpu, nvidia, cuda, repo]

- name: Get available NVIDIA server driver versions
  ansible.builtin.shell: |
    set -o pipefail
    # Search for server drivers first (preferred for server environments)
    apt-cache search "nvidia-driver-[0-9].*-server" | grep -o "nvidia-driver-[0-9][0-9][0-9]*-server" | sort -V | tail -5
  register: available_server_drivers
  changed_when: false
  failed_when: false
  args:
    executable: /bin/bash
  tags: [gpu, nvidia, drivers]

- name: Get available NVIDIA desktop driver versions (fallback)
  ansible.builtin.shell: |
    set -o pipefail
    # Fallback to desktop drivers if no server drivers found
    apt-cache search "nvidia-driver-[0-9]" | grep "^nvidia-driver-[0-9]" | grep -v server | grep -o "nvidia-driver-[0-9][0-9][0-9]*" | sort -V | tail -5
  register: available_desktop_drivers
  changed_when: false
  failed_when: false
  args:
    executable: /bin/bash
  tags: [gpu, nvidia, drivers]

- name: Set preferred driver (force nvidia-driver-570-server for consistency)
  ansible.builtin.set_fact:
    selected_driver: "nvidia-driver-570-server"
    selected_driver_version: "570"
    is_server_driver: true
  tags: [gpu, nvidia, drivers]

- name: Display selected NVIDIA driver
  ansible.builtin.debug:
    msg:
      - "Server drivers available: {{ available_server_drivers.stdout_lines }}"
      - "Desktop drivers available: {{ available_desktop_drivers.stdout_lines }}"
      - "Selected driver: {{ selected_driver }}"
      - "Driver version: {{ selected_driver_version }}"
      - "Is server driver: {{ is_server_driver }}"
  tags: [gpu, nvidia, drivers, info]

- name: Clean package cache and fix dependencies
  ansible.builtin.apt:
    update_cache: true
    autoclean: true
  become: true
  tags: [gpu, nvidia, drivers, cleanup]

- name: Fix broken packages after cleanup
  ansible.builtin.apt:
    state: fixed
  become: true
  when: true
  failed_when: false
  tags: [gpu, nvidia, drivers, fix]

- name: Install selected NVIDIA driver
  ansible.builtin.apt:
    name: "{{ selected_driver }}"
    state: present
  become: true
  when: true
  register: nvidia_driver_install
  tags: [gpu, nvidia, drivers]

- name: Install matching NVIDIA utilities
  ansible.builtin.apt:
    name: "nvidia-utils-{{ selected_driver_version }}{% if is_server_driver %}-server{% endif %}"
    state: present
  become: true
  when: true
  register: nvidia_utils_install
  tags: [gpu, nvidia, drivers]

- name: Get current kernel version
  ansible.builtin.command: uname -r
  register: kernel_version
  changed_when: false
  tags: [gpu, nvidia, drivers]

- name: Install NVIDIA kernel modules for current kernel
  ansible.builtin.apt:
    name: "linux-modules-nvidia-{{ selected_driver_version }}{% if is_server_driver %}-server{% endif %}-generic"
    state: present
  become: true
  when: true
  tags: [gpu, nvidia, drivers]

- name: Install NVIDIA settings (if available)
  ansible.builtin.apt:
    name: nvidia-settings
    state: present
  become: true
  when: true
  failed_when: false
  tags: [gpu, nvidia, drivers]

- name: Check if NVIDIA kernel modules are loaded
  ansible.builtin.shell: |
    set -o pipefail
    lsmod | grep nvidia || echo "NO_MODULES"
  register: nvidia_modules_check
  changed_when: false
  failed_when: false
  args:
    executable: /bin/bash
  tags: [gpu, nvidia, drivers, verify]

- name: Try to load NVIDIA kernel modules
  ansible.builtin.shell: |
    modprobe nvidia 2>/dev/null || echo "Module load failed - reboot required"
    modprobe nvidia-modeset 2>/dev/null || true
    modprobe nvidia-drm 2>/dev/null || true
  become: true
  when: "'NO_MODULES' in nvidia_modules_check.stdout"
  failed_when: false
  changed_when: false
  tags: [gpu, nvidia, drivers]

- name: Wait for apt lock to be released
  ansible.builtin.shell: |
    while fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
      echo "Waiting for other apt processes to finish..."
      sleep 5
    done
    echo "APT lock released"
  become: true
  changed_when: false
  tags: [gpu, nvidia, cuda]

- name: Install CUDA toolkit 12.8 (compatible with nvidia-driver-570-server)
  ansible.builtin.apt:
    name: "cuda-toolkit-12-8"
    state: present
  become: true
  tags: [gpu, nvidia, cuda]

- name: Install additional CUDA packages for complete toolkit
  ansible.builtin.apt:
    name:
      - cuda-compiler-12-8
      - cuda-nvcc-12-8
      - cuda-tools-12-8
      - cuda-cccl-12-8
    state: present
  become: true
  failed_when: false # Some packages might not be available
  tags: [gpu, nvidia, cuda]

- name: Install cuDNN for deep learning (optional)
  ansible.builtin.apt:
    name:
      - libcudnn8
      - libcudnn8-dev
    state: present
  become: true
  failed_when: false # May not be available in all repositories
  tags: [gpu, nvidia, cudnn]

# Phase 3: Environment Configuration - Critical for command accessibility
- name: Check if CUDA installation directory exists
  ansible.builtin.stat:
    path: "/usr/local/cuda-12.8"
  register: cuda_install_dir
  tags: [gpu, nvidia, cuda, environment]

- name: Create CUDA symbolic link for version compatibility
  ansible.builtin.file:
    src: "/usr/local/cuda-12.8"
    dest: "/usr/local/cuda"
    state: link
    force: true
  become: true
  when: cuda_install_dir.stat.exists
  tags: [gpu, nvidia, cuda, environment]

- name: Configure CUDA environment variables in /etc/environment
  ansible.builtin.blockinfile:
    path: "/etc/environment"
    marker: "# {mark} ANSIBLE MANAGED - CUDA 12.8 Environment Variables"
    block: |
      CUDA_HOME="/usr/local/cuda"
      CUDA_PATH="/usr/local/cuda"
      LD_LIBRARY_PATH="/usr/local/cuda/lib64:/usr/local/cuda/lib"
    create: true
    mode: "0644"
  become: true
  tags: [gpu, nvidia, cuda, environment]

- name: Create system-wide CUDA profile script for all users
  ansible.builtin.copy:
    content: |
      #!/bin/bash
      # CUDA 12.8 Environment Configuration
      # This script is sourced by all interactive shell sessions

      # Only configure if CUDA directory exists
      if [ -d "/usr/local/cuda" ]; then
          # Set CUDA environment variables
          export CUDA_HOME="/usr/local/cuda"
          export CUDA_PATH="/usr/local/cuda"

          # Add CUDA binaries to PATH if not already present and PATH exists
          if [ -n "$PATH" ] && [[ ":$PATH:" != *":/usr/local/cuda/bin:"* ]]; then
              export PATH="/usr/local/cuda/bin:$PATH"
          elif [ -z "$PATH" ]; then
              export PATH="/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
          fi

          # Add CUDA libraries to LD_LIBRARY_PATH if not already present
          if [ -n "$LD_LIBRARY_PATH" ]; then
              if [[ ":$LD_LIBRARY_PATH:" != *":/usr/local/cuda/lib64:"* ]]; then
                  export LD_LIBRARY_PATH="/usr/local/cuda/lib64:$LD_LIBRARY_PATH"
              fi
              if [[ ":$LD_LIBRARY_PATH:" != *":/usr/local/cuda/lib:"* ]]; then
                  export LD_LIBRARY_PATH="/usr/local/cuda/lib:$LD_LIBRARY_PATH"
              fi
          else
              export LD_LIBRARY_PATH="/usr/local/cuda/lib64:/usr/local/cuda/lib"
          fi
      fi
    dest: "/etc/profile.d/cuda.sh"
    mode: "0755"
    owner: root
    group: root
  become: true
  tags: [gpu, nvidia, cuda, environment]

- name: Remove legacy CUDA environment block from ~/.bashrc (zsh migration)
  ansible.builtin.blockinfile:
    path: "{{ ansible_user_dir }}/.bashrc"
    marker: "# {mark} ANSIBLE MANAGED - CUDA 12.8 Environment"
    state: absent
    create: false
  become: true
  become_user: "{{ ansible_user }}"
  failed_when: false
  tags: [gpu, nvidia, cuda, environment, cleanup]

- name: Create system-wide alternative for nvcc command access
  ansible.builtin.file:
    src: "/usr/local/cuda/bin/nvcc"
    dest: "/usr/local/bin/nvcc"
    state: link
    force: true
  become: true
  when: cuda_install_dir.stat.exists
  failed_when: false
  tags: [gpu, nvidia, cuda, environment]

- name: Ensure nvcc symlink exists even if CUDA symlink missing
  ansible.builtin.shell: |
    set -o pipefail
    if [ ! -f /usr/local/bin/nvcc ]; then
        NVCC_PATH=$(find /usr/local -maxdepth 3 -type f -name "nvcc" 2>/dev/null | head -1)
        if [ -n "$NVCC_PATH" ]; then
            ln -sf "$NVCC_PATH" /usr/local/bin/nvcc
        fi
    fi
  become: true
  failed_when: false
  args:
    executable: /bin/bash
  changed_when: false
  tags: [gpu, nvidia, cuda, environment]

- name: Create system-wide alternative for nvidia-smi command access
  ansible.builtin.shell: |
    set -o pipefail
    # Determine nvidia-smi location and create a stable symlink
    NVIDIA_SMI_PATH="$(command -v nvidia-smi 2>/dev/null || true)"
    if [ -z "$NVIDIA_SMI_PATH" ]; then
        NVIDIA_SMI_PATH=$(find /usr/bin /usr/local/bin /usr/lib /usr/lib/nvidia* /usr/lib/x86_64-linux-gnu -type f -name "nvidia-smi" 2>/dev/null | head -1)
    fi
    if [ -n "$NVIDIA_SMI_PATH" ] && [ "$NVIDIA_SMI_PATH" != "/usr/local/bin/nvidia-smi" ]; then
        ln -sf "$NVIDIA_SMI_PATH" /usr/local/bin/nvidia-smi
    fi
  become: true
  failed_when: false
  changed_when: false
  args:
    executable: /bin/bash
  tags: [gpu, nvidia, drivers, environment]

- name: Configure dynamic linker for CUDA libraries
  ansible.builtin.copy:
    content: |
      /usr/local/cuda/lib64
      /usr/local/cuda/lib
    dest: "/etc/ld.so.conf.d/cuda.conf"
    mode: "0644"
    owner: root
    group: root
  become: true
  tags: [gpu, nvidia, cuda, environment]

- name: Refresh dynamic linker cache
  ansible.builtin.command: ldconfig
  become: true
  changed_when: false
  tags: [gpu, nvidia, cuda, environment]

- name: Install GPU monitoring tools
  ansible.builtin.pip:
    name:
      - nvidia-ml-py3
      - gpustat
    state: present
    executable: pip3
  become: true
  failed_when: false # May not be available before reboot
  tags: [gpu, nvidia, monitoring]

# Reboot so subsequent verification runs in a fresh post-install environment
- name: Reboot to finalize NVIDIA driver installation if required
  ansible.builtin.reboot:
    msg: "Rebooting to finalize NVIDIA driver installation"
    reboot_timeout: 1800
    connect_timeout: 30
    pre_reboot_delay: 0
    post_reboot_delay: 15
  when:
    - (nvidia_driver_install is defined and nvidia_driver_install.changed) or (nvidia_utils_install is defined and nvidia_utils_install.changed) or
      (nvidia_modules_check is defined and 'NO_MODULES' in nvidia_modules_check.stdout)
  become: true
  tags: [gpu, nvidia, reboot]

# Phase 4: Comprehensive Verification and Testing
- name: Verify NVIDIA driver installation (post-installation)
  ansible.builtin.shell: |
    set -o pipefail
    # First check if nvidia-smi is available in PATH
    if command -v nvidia-smi >/dev/null 2>&1; then
        nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv,noheader
    elif [ -f "/usr/bin/nvidia-smi" ]; then
        /usr/bin/nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv,noheader
    else
        echo "NVIDIA_SMI_NOT_FOUND - reboot required"
    fi
  register: gpu_verification
  changed_when: false
  failed_when: false
  args:
    executable: /bin/bash
  tags: [gpu, nvidia, verify]

- name: Verify CUDA toolkit installation
  ansible.builtin.shell: |
    set -o pipefail
    # Check multiple possible nvcc locations
    if command -v nvcc >/dev/null 2>&1; then
        nvcc --version | grep "release"
    elif [ -f "/usr/local/cuda/bin/nvcc" ]; then
        /usr/local/cuda/bin/nvcc --version | grep "release"
    elif [ -f "/usr/local/cuda-12.8/bin/nvcc" ]; then
        /usr/local/cuda-12.8/bin/nvcc --version | grep "release"
    else
        echo "NVCC_NOT_FOUND - installation may have failed or reboot required"
    fi
  register: cuda_verification
  changed_when: false
  failed_when: false
  environment:
    PATH: "/usr/local/cuda/bin:/usr/local/cuda-12.8/bin:{{ ansible_env.PATH }}"
  args:
    executable: /bin/bash
  tags: [gpu, nvidia, cuda, verify]

- name: Check CUDA library files installation
  ansible.builtin.shell: |
    set -o pipefail
    # Verify key CUDA libraries are installed
    CUDA_LIBS_FOUND=0
    for path in "/usr/local/cuda/lib64" "/usr/local/cuda-12.8/lib64"; do
        if [ -d "$path" ] && [ "$(ls -A $path 2>/dev/null)" ]; then
            echo "CUDA libraries found in: $path"
            ls "$path"/libcudart* 2>/dev/null | head -3
            CUDA_LIBS_FOUND=1
            break
        fi
    done
    if [ $CUDA_LIBS_FOUND -eq 0 ]; then
        echo "CUDA_LIBS_NOT_FOUND - installation may be incomplete"
    fi
  register: cuda_libs_verification
  changed_when: false
  failed_when: false
  args:
    executable: /bin/bash
  tags: [gpu, nvidia, cuda, verify]

- name: Test environment variable accessibility
  ansible.builtin.shell: |
    set -o pipefail
    # Test if CUDA environment is properly configured
    echo "PATH check:"
    echo "$PATH" | grep -o "/usr/local/cuda[^:]*" || echo "CUDA not in PATH"
    echo "LD_LIBRARY_PATH check:"
    echo "${LD_LIBRARY_PATH:-empty}" | grep -o "/usr/local/cuda[^:]*" || echo "CUDA not in LD_LIBRARY_PATH"
    echo "CUDA_HOME: ${CUDA_HOME:-not_set}"
  register: env_verification
  changed_when: false
  failed_when: false
  environment:
    CUDA_HOME: "/usr/local/cuda"
    PATH: "/usr/local/cuda/bin:{{ ansible_env.PATH }}"
    LD_LIBRARY_PATH: "/usr/local/cuda/lib64:/usr/local/cuda/lib:{{ ansible_env.LD_LIBRARY_PATH | default('') }}"
  args:
    executable: /bin/bash
  tags: [gpu, nvidia, environment, verify]

- name: Advanced CUDA runtime verification (if available)
  ansible.builtin.shell: |
    # Test CUDA runtime compilation if nvcc is available
    if command -v nvcc >/dev/null 2>&1; then
        echo "CUDA_NVCC_AVAILABLE - nvcc is in PATH"
        nvcc --version
    elif [ -f "/usr/local/cuda/bin/nvcc" ]; then
        echo "CUDA_NVCC_FOUND - nvcc found in /usr/local/cuda/bin/"
        /usr/local/cuda/bin/nvcc --version
    elif [ -f "/usr/local/cuda-12.8/bin/nvcc" ]; then
        echo "CUDA_NVCC_FOUND - nvcc found in /usr/local/cuda-12.8/bin/"
        /usr/local/cuda-12.8/bin/nvcc --version
    else
        echo "NVCC_NOT_AVAILABLE - cannot find nvcc compiler"
    fi
  register: cuda_compile_test
  changed_when: false
  failed_when: false
  environment:
    PATH: "/usr/local/cuda/bin:/usr/local/cuda-12.8/bin:{{ ansible_env.PATH }}"
    LD_LIBRARY_PATH: "/usr/local/cuda/lib64:/usr/local/cuda/lib:{{ ansible_env.LD_LIBRARY_PATH | default('') }}"
  tags: [gpu, nvidia, cuda, verify, advanced]

- name: Display comprehensive installation results
  ansible.builtin.debug:
    msg:
      - "CUDA 12.8 Installation Complete with nvidia-driver-570-server"
      - "Hardware: {{ (nvidia_hardware_check.stdout_lines[0] | default('No NVIDIA GPU detected')) | regex_replace('^[0-9:]+\\s+', '') }}"
      - "Driver: {{ gpu_verification.stdout if gpu_verification.stdout != 'NVIDIA_SMI_NOT_FOUND - reboot required' else 'Requires reboot' }}"
      - "CUDA: {{ cuda_verification.stdout if cuda_verification.stdout != 'NVCC_NOT_FOUND - installation may have failed or reboot required' else 'Requires reboot'
        }}"
      - "Libraries: {{ cuda_libs_verification.stdout_lines[0] if cuda_libs_verification.stdout_lines else 'Verification pending' }}"
      - "Kernel modules: {% if 'NO_MODULES' not in nvidia_modules_check.stdout %}{{ nvidia_modules_check.stdout_lines | length }} modules loaded{% else %}Require
        reboot{% endif %}"
      - "Next: Reboot system, then test with 'nvidia-smi' and 'nvcc --version'"
  tags: [gpu, nvidia, info, summary]

- name: Clean up temporary files
  ansible.builtin.file:
    path: "/tmp/cuda-keyring_1.1-1_all.deb"
    state: absent
  become: true
  tags: [gpu, nvidia, cleanup]
