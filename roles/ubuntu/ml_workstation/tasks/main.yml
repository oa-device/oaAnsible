---
# Ubuntu ML Workstation Setup Tasks

- name: Check if running on Ubuntu
  fail:
    msg: "This role is designed for Ubuntu systems only"
  when: ansible_distribution != "Ubuntu"
  tags: [always]

- name: Display system information
  debug:
    msg:
      - "Setting up Ubuntu ML training server"
      - "Distribution: {{ ansible_distribution }} {{ ansible_distribution_version }}"
      - "Architecture: {{ ansible_architecture }}"
  tags: [info]

# System package updates and essentials
- name: Update apt package cache
  apt:
    update_cache: yes
    cache_valid_time: 3600
  become: true
  tags: [setup, packages]

- name: Install essential system packages
  apt:
    name: "{{ ubuntu_ml_packages.system_packages }}"
    state: present
  become: true
  tags: [setup, packages]

- name: Install monitoring and development packages
  apt:
    name: "{{ ubuntu_ml_packages.monitoring_packages }}"
    state: present
  become: true
  tags: [setup, packages, monitoring]

# System optimizations for ML training
- name: Increase shared memory size for ML training
  lineinfile:
    path: /etc/fstab
    line: "tmpfs /dev/shm tmpfs defaults,size=8G 0 0"
    backup: yes
  become: true
  when: ubuntu_ml_optimization.increase_shared_memory
  tags: [setup, optimization]

- name: Configure swap settings for ML workloads
  sysctl:
    name: "{{ item.key }}"
    value: "{{ item.value }}"
    state: present
    reload: yes
  loop:
    - { key: "vm.swappiness", value: "10" }
    - { key: "vm.vfs_cache_pressure", value: "50" }
  become: true
  when: ubuntu_ml_optimization.optimize_swap
  tags: [setup, optimization]

- name: Increase file descriptor limits
  lineinfile:
    path: /etc/security/limits.conf
    line: "{{ item }}"
    backup: yes
  loop:
    - "* soft nofile 65536"
    - "* hard nofile 65536"
    - "{{ ansible_user }} soft nofile 65536"
    - "{{ ansible_user }} hard nofile 65536"
  become: true
  when: ubuntu_ml_optimization.increase_file_limits
  tags: [setup, optimization]

# GPU Setup (NVIDIA)
- name: Check for NVIDIA GPU
  shell: lspci | grep -i nvidia
  register: nvidia_check
  ignore_errors: yes
  changed_when: false
  tags: [setup, gpu]

- name: Display GPU information
  debug:
    msg: "{{ 'NVIDIA GPU detected' if nvidia_check.rc == 0 else 'No NVIDIA GPU found' }}"
  tags: [info, gpu]

- name: Install NVIDIA drivers and CUDA (if GPU present)
  include_tasks: nvidia_setup.yml
  when: nvidia_check.rc == 0 and nvidia_config.install_drivers
  tags: [setup, gpu, nvidia]

# Create ML data directories
- name: Create ML datasets directory
  file:
    path: "{{ data_management.datasets_path }}"
    state: directory
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"
    mode: "0755"
  become: true
  when: data_management.create_datasets_dir
  tags: [setup, data]

- name: Link datasets directory to oaSentinel
  file:
    src: "{{ data_management.datasets_path }}"
    dest: "{{ oasentinel_install_dir }}/data/shared"
    state: link
    owner: "{{ ansible_user }}"
  when: data_management.create_datasets_dir
  tags: [setup, data]

# Performance governor for training
- name: Set CPU governor to performance
  shell: |
    echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
  become: true
  when: ubuntu_ml_optimization.enable_performance_governor
  tags: [setup, performance]

- name: Make performance governor persistent
  cron:
    name: "Set CPU governor to performance"
    special_time: reboot
    job: "echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor"
    user: root
  become: true
  when: ubuntu_ml_optimization.enable_performance_governor
  tags: [setup, performance]

# Training environment setup
- name: Create screen session for training
  template:
    src: ml_training_screen.sh.j2
    dest: "{{ ansible_user_dir }}/start_ml_training.sh"
    owner: "{{ ansible_user }}"
    mode: "0755"
  when: training_server.setup_screen_sessions
  tags: [setup, training]

- name: Setup Jupyter Lab for remote access
  template:
    src: jupyter_config.py.j2
    dest: "{{ ansible_user_dir }}/.jupyter/jupyter_lab_config.py"
    owner: "{{ ansible_user }}"
    mode: "0644"
  when: training_server.enable_jupyter
  tags: [setup, jupyter]

- name: Create Jupyter service script
  template:
    src: start_jupyter.sh.j2
    dest: "{{ ansible_user_dir }}/start_jupyter.sh"
    owner: "{{ ansible_user }}"
    mode: "0755"
  when: training_server.enable_jupyter
  tags: [setup, jupyter]

# GPU monitoring setup
- name: Install GPU monitoring script
  template:
    src: gpu_monitor.sh.j2
    dest: "{{ oasentinel_install_dir }}/scripts/gpu_monitor.sh"
    owner: "{{ ansible_user }}"
    mode: "0755"
  when: nvidia_check.rc == 0
  tags: [setup, monitoring]

- name: Create Ubuntu-specific training configuration
  template:
    src: ubuntu_training_config.yaml.j2
    dest: "{{ oasentinel_install_dir }}/configs/ubuntu_gpu.yaml"
    owner: "{{ ansible_user }}"
    mode: "0644"
  tags: [setup, config]

# Training aliases and environment
- name: Add Ubuntu ML training aliases
  blockinfile:
    path: "{{ ansible_user_dir }}/.bashrc"
    marker: "# {mark} ANSIBLE MANAGED - Ubuntu ML Training"
    block: |
      # Ubuntu ML Training Environment
      export CUDA_VISIBLE_DEVICES=0  # Adjust for multi-GPU setup
      export TOKENIZERS_PARALLELISM=false  # Avoid tokenizer warnings

      # Training aliases
      alias train-gpu="cd $OASENTINEL_HOME && source .venv/bin/activate && python scripts/train.sh --config configs/ubuntu_gpu.yaml"
      alias gpu-watch="watch -n 1 'nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total,temperature.gpu --format=csv,noheader,nounits'"
      alias gpu-top="gpustat -i 1"
      alias train-screen="screen -S ml-training ./start_ml_training.sh"
      alias jupyter-start="./start_jupyter.sh"

      # Training functions
      gpu-status() {
          echo "üöÄ GPU Status:"
          nvidia-smi --query-gpu=name,utilization.gpu,memory.used,memory.total,temperature.gpu --format=csv,noheader,nounits
      }

      training-log() {
          tail -f $OASENTINEL_HOME/logs/training/*.log 2>/dev/null || echo "No training logs found"
      }

    create: yes
  tags: [setup, aliases]

# System verification
- name: Run Ubuntu ML verification
  shell: |
    cd "{{ oasentinel_install_dir }}"
    source .venv/bin/activate
    python -c "
    import torch
    import platform
    print('üöÄ Ubuntu ML Server Verification')
    print('=' * 40)
    print(f'Platform: {platform.platform()}')
    print(f'PyTorch Version: {torch.__version__}')
    print(f'CUDA Available: {torch.cuda.is_available()}')
    if torch.cuda.is_available():
        print(f'CUDA Version: {torch.version.cuda}')
        print(f'GPU Count: {torch.cuda.device_count()}')
        for i in range(torch.cuda.device_count()):
            print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
        print('‚úÖ GPU acceleration ready for training!')
    else:
        print('‚ö†Ô∏è  CUDA not available - CPU training only')
    print('Ubuntu ML server setup complete! üéØ')
    "
  become_user: "{{ ansible_user }}"
  register: ubuntu_verification
  tags: [verify]

- name: Display verification results
  debug:
    msg: "{{ ubuntu_verification.stdout_lines }}"
  tags: [verify]

- name: Ubuntu ML setup summary
  debug:
    msg:
      - "üöÄ Ubuntu ML Training Server Setup Complete!"
      - "GPU Support: {{ 'Enabled' if nvidia_check.rc == 0 else 'CPU Only' }}"
      - "oaSentinel: {{ oasentinel_install_dir }}"
      - "Datasets: {{ data_management.datasets_path if data_management.create_datasets_dir else 'In project directory' }}"
      - "Jupyter: {{ 'Enabled on port ' + training_server.jupyter_port|string if training_server.enable_jupyter else 'Disabled' }}"
      - "Use 'train-gpu' for optimized training"
      - "Use 'gpu-watch' to monitor GPU usage"
  tags: [summary]
