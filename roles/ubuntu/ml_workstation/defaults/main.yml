---
# Ubuntu ML Workstation Role Defaults
# Ubuntu-specific settings for ML training servers

# NVIDIA/CUDA Configuration
ubuntu_nvidia_config:
  install_drivers: true
  install_cuda: true
  install_cudnn: true
  cuda_version: "12.1" # Compatible with PyTorch 2.0+
  driver_version: "latest"

# System optimization for ML workloads
ubuntu_ml_optimization:
  increase_shared_memory: true
  optimize_swap: true
  increase_file_limits: true
  install_build_essentials: true
  enable_performance_governor: true

# ML Development packages
ubuntu_ml_packages:
  system_packages:
    - build-essential
    - cmake
    - pkg-config
    - python3-dev
    - python3-pip
    - python3-venv
    - libssl-dev
    - libffi-dev
    - libbz2-dev
    - libreadline-dev
    - libsqlite3-dev
    - libncursesw5-dev
    - libgdbm-dev
    - liblzma-dev
    - tk-dev
    - uuid-dev
    - git
    - git-lfs
    - curl
    - wget
    - unzip
    - imagemagick

  # OpenCV and media packages (install separately to handle dependencies)
  opencv_packages:
    - libjpeg-dev
    - libtiff5-dev
    - libpng-dev
    - libavcodec-dev
    - libavformat-dev
    - libswscale-dev
    - libv4l-dev
    - libxvidcore-dev
    - libx264-dev
    - libgtk-3-dev
    - libatlas-base-dev
    - gfortran
    - libhdf5-dev
    # OpenGL libraries for headless OpenCV operations (Ubuntu 22.04+ compatible)
    - libgl1-mesa-dri
    - libgl1
    - libglx-mesa0
    - libglib2.0-0t64
    - libsm6
    - libxext6
    - libxrender1
    - libxrender-dev
    - libgomp1
    - libegl1
    - pkg-config

  monitoring_packages:
    - htop
    - iotop
    - nvidia-ml-py3
    - gpustat
    - screen
    - tmux

# Docker configuration for ML
ubuntu_docker_ml_config:
  install_nvidia_runtime: true
  enable_gpu_support: true
  create_ml_networks: true

# Training server configuration
ubuntu_training_server:
  enable_jupyter: true
  jupyter_port: 8888
  enable_tensorboard: true
  tensorboard_port: 6006
  enable_ssh_tunnel: true
  setup_screen_sessions: true

# Remote access and monitoring
ubuntu_remote_access:
  enable_vnc: false # Only if GUI needed
  setup_reverse_tunnel: false
  monitoring_dashboard: true

# Data management
ubuntu_data_management:
  create_datasets_dir: true
  setup_nfs_mount: false
  optimize_io: true
  datasets_path: "/data/ml-datasets"

# CrowdHuman Dataset Configuration - Shared Location
ubuntu_crowdhuman_dataset:
  # Use shared location for bandwidth efficiency across projects
  base_path: "{{ ansible_user_dir }}/CrowdHuman"
  raw_path: "{{ ansible_user_dir }}/CrowdHuman/raw"
  processed_path: "{{ ansible_user_dir }}/CrowdHuman/processed"
  config_path: "{{ ansible_user_dir }}/CrowdHuman/configs"
  # Migration from old project-specific location
  old_project_path: "{{ ansible_user_dir }}/oaSentinel/data/raw/crowdhuman"

# oaSentinel Configuration
ubuntu_oasentinel:
  repo_url: "https://github.com/oa-device/oaSentinel.git"
  branch: "main"
  install_dir: "{{ ansible_user_dir }}/oaSentinel"
  force_update: false

  # Training Configuration
  model_arch: "yolo11m" # YOLOv11 Medium as specified
  epochs: 100 # Default training epochs
  batch_size: 16 # Default batch size (adjust based on GPU memory)
  input_size: 640 # Input image size
  config_file: "configs/ubuntu_gpu.yaml"

  # GPU Configuration
  device: "0" # Use first GPU by default
  mixed_precision: true # Enable AMP for faster training
  cuda_devices: "0" # CUDA_VISIBLE_DEVICES

  # Dataset Configuration
  dataset_name: "crowdhuman"
  auto_download: true # Automatically download datasets
  auto_process: true # Automatically process datasets
  validate_data: true # Validate dataset before training

  # Experiment Tracking
  wandb_enabled: false # Disable W&B by default (can be enabled per deployment)
  wandb_mode: "disabled" # disabled/online/offline
  wandb_project: "oaSentinel"
  # wandb_api_key: ""              # Set in inventory vars if needed
  # wandb_entity: ""               # Set in inventory vars if needed

  # Training Optimization
  use_pretrained: true # Use pretrained YOLO weights
  learning_rate: 0.001 # Initial learning rate
  optimizer: "AdamW" # Optimizer choice
  scheduler: "cosine" # Learning rate scheduler
  patience: 10 # Early stopping patience
  workers: 4 # DataLoader workers (will be adjusted based on CPU)

  # Validation Configuration
  val_split: 0.2 # Validation split ratio
  test_split: 0.1 # Test split ratio
  conf_threshold: 0.25 # Confidence threshold for predictions
  iou_threshold: 0.45 # IoU threshold for NMS

  # Training Pipeline
  warmup_epochs: 3 # Warmup epochs
  auto_resume: true # Auto-resume from last checkpoint
  early_stopping: true # Enable early stopping
  auto_evaluate: true # Auto-evaluate after training
  auto_export: false # Auto-export models (disabled by default)

  # Deployment Configuration
  deploy_format: "coreml" # Default export format for macOS deployment
  optimization_level: "balanced" # speed/accuracy/balanced
  quantization: false # Model quantization
  deploy_to_tracker: false # Auto-deploy to oaTracker

  # Development Configuration
  environment: "production" # production/development/testing
  debug: false # Enable debug mode
  log_level: "INFO" # Logging level
  disable_tqdm: false # Disable progress bars

  # System Configuration
  temp_dir: "/tmp" # Temporary directory
  shared_memory_size: "8G" # Shared memory for data loading
  tokenizers_parallel: false # Avoid tokenizer warnings
