# oaSentinel Ubuntu GPU Training Configuration
# Generated by Ansible for {{ inventory_hostname }}
# Optimized for {{ ansible_processor_vcpus | default(4) }} CPU cores, {{ ((ansible_memtotal_mb | default(8192))/1024)|round|int }}GB RAM
{% if ml_has_nvidia_gpu is defined and ml_has_nvidia_gpu %}
# GPU Configuration: {{ ansible_facts.get('gpu_info', 'NVIDIA GPU detected') }}
{% endif %}

# Model Configuration
model:
  architecture: "{{ ubuntu_oasentinel.model_arch | default('yolo11m') }}"  # YOLOv11 Medium as specified
  pretrained: {{ ubuntu_oasentinel.use_pretrained | default(true) }}
  input_size: {{ ubuntu_oasentinel.input_size | default(640) }}

# Dataset Configuration  
dataset:
  name: "{{ ubuntu_oasentinel.dataset_name | default('crowdhuman') }}"
  path: "data/processed/crowdhuman"
  classes: ["person", "head"]  # Human detection focus
  image_size: {{ ubuntu_oasentinel.input_size | default(640) }}
  batch_size: {{ ubuntu_oasentinel.batch_size | default(ubuntu_ml_training.batch_size | default(16)) }}
  
# Training Configuration
training:
  epochs: {{ ubuntu_oasentinel.epochs | default(ubuntu_ml_training.epochs | default(100)) }}
  batch_size: {{ ubuntu_oasentinel.batch_size | default(ubuntu_ml_training.batch_size | default(16)) }}
  learning_rate: {{ ubuntu_oasentinel.learning_rate | default(0.001) }}
  optimizer: "{{ ubuntu_oasentinel.optimizer | default('AdamW') }}"
  scheduler: "{{ ubuntu_oasentinel.scheduler | default('cosine') }}"
  patience: {{ ubuntu_oasentinel.patience | default(10) }}
  workers: {{ ubuntu_oasentinel.workers | default(ansible_processor_vcpus | default(4)) }}
  
  # Mixed precision training for GPU optimization
{% if ml_has_nvidia_gpu is defined and ml_has_nvidia_gpu %}
  amp: {{ ubuntu_oasentinel.mixed_precision | default(true) }}  # Automatic Mixed Precision
{% else %}
  amp: false  # Disable AMP for CPU training
{% endif %}
  
  # Data augmentation
  augment:
    hsv_h: 0.015      # Hue augmentation
    hsv_s: 0.7        # Saturation augmentation  
    hsv_v: 0.4        # Value augmentation
    degrees: 0.0      # Rotation (disabled for human detection)
    translate: 0.1    # Translation
    scale: 0.5        # Scale augmentation
    shear: 0.0        # Shear (disabled)
    perspective: 0.0  # Perspective (disabled)
    flipud: 0.0       # Vertical flip (disabled for humans)
    fliplr: 0.5       # Horizontal flip
    mixup: 0.0        # MixUp augmentation (disabled)
    copy_paste: 0.0   # Copy-paste augmentation (disabled)

# Hardware Optimization
hardware:
{% if ml_has_nvidia_gpu is defined and ml_has_nvidia_gpu %}
  device: "{{ ubuntu_oasentinel.device | default('0') }}"  # Use first GPU
  gpu_memory_fraction: {{ ubuntu_oasentinel.gpu_memory_fraction | default(0.95) }}
{% else %}
  device: "cpu"
  cpu_threads: {{ ansible_processor_vcpus | default(4) }}
{% endif %}
  
  # System optimization
  dataloader_workers: {{ [ansible_processor_vcpus | default(4), 8] | min }}
  pin_memory: {{ ml_has_nvidia_gpu is defined and ml_has_nvidia_gpu }}
  persistent_workers: true

# Experiment Tracking
experiment:
  project_name: "oaSentinel"
  experiment_name: "ubuntu_{{ inventory_hostname }}_{{ ansible_date_time.epoch }}"
  tags: 
    - "ubuntu"
    - "{{ inventory_hostname }}"
    - "{{ ubuntu_oasentinel.model_arch | default('yolo11m') }}"
{% if ml_has_nvidia_gpu is defined and ml_has_nvidia_gpu %}
    - "gpu"
{% else %}
    - "cpu"
{% endif %}
  
  # Weights & Biases configuration
  wandb:
    enabled: {{ ubuntu_oasentinel.wandb_enabled | default(false) }}
    project: "oaSentinel"
    entity: "{{ ubuntu_oasentinel.wandb_entity | default('') }}"
    notes: "Ubuntu training on {{ inventory_hostname }}"

# Output Configuration
output:
  save_dir: "models/checkpoints"
  save_period: 10  # Save checkpoint every 10 epochs
  save_best: true
  save_last: true
  
  # Export formats for deployment
  export_formats: ["pt", "onnx", "coreml"]  # PyTorch, ONNX, CoreML
  
# Validation Configuration  
validation:
  val_split: {{ ubuntu_oasentinel.val_split | default(0.2) }}
  test_split: {{ ubuntu_oasentinel.test_split | default(0.1) }}
  confidence_threshold: {{ ubuntu_oasentinel.conf_threshold | default(0.25) }}
  iou_threshold: {{ ubuntu_oasentinel.iou_threshold | default(0.45) }}

# System Monitoring
monitoring:
  log_interval: 10  # Log every 10 batches
  plot_losses: true
  plot_metrics: true
  save_txt: true    # Save predictions in txt format
  save_conf: true   # Save confidence scores
  
# Ubuntu-specific Optimizations
ubuntu_optimizations:
  # Memory management
  max_memory_usage: {{ ((ansible_memtotal_mb | default(8192)) * 0.8) | round | int }}MB
  shared_memory: "{{ ubuntu_ml_optimization.shared_memory_size | default('8G') }}"
  
  # CPU governor
  cpu_governor: "performance"
  
  # I/O optimization  
  io_scheduler: "deadline"
  
  # Network optimization (for distributed training if needed)
  tcp_congestion_control: "bbr"

# Training Pipeline Configuration
pipeline:
  # Data preparation
  download_dataset: {{ ubuntu_oasentinel.auto_download | default(true) }}
  process_dataset: {{ ubuntu_oasentinel.auto_process | default(true) }}
  validate_dataset: {{ ubuntu_oasentinel.validate_data | default(true) }}
  
  # Training phases
  warmup_epochs: {{ ubuntu_oasentinel.warmup_epochs | default(3) }}
  auto_resume: {{ ubuntu_oasentinel.auto_resume | default(true) }}
  early_stopping: {{ ubuntu_oasentinel.early_stopping | default(true) }}
  
  # Post-training
  auto_evaluate: {{ ubuntu_oasentinel.auto_evaluate | default(true) }}
  auto_export: {{ ubuntu_oasentinel.auto_export | default(false) }}

# Deployment Configuration (for oaTracker integration)
deployment:
  target_format: "{{ ubuntu_oasentinel.deploy_format | default('coreml') }}"  # For macOS deployment
  optimization_level: "{{ ubuntu_oasentinel.optimization_level | default('balanced') }}"  # speed/accuracy/balanced
  quantization: {{ ubuntu_oasentinel.quantization | default(false) }}
  
  # Integration with oaTracker
  tracker_deployment:
    enabled: {{ ubuntu_oasentinel.deploy_to_tracker | default(false) }}
    tracker_host: "{{ ubuntu_oasentinel.tracker_host | default('') }}"
    model_name: "oaSentinel_{{ ubuntu_oasentinel.model_arch | default('yolo11m') }}"

# Advanced Configuration
advanced:
  # Distributed training (for multi-GPU setup)
  distributed: false
  world_size: 1
  
  # Gradient optimization
  gradient_clip: {{ ubuntu_oasentinel.gradient_clip | default(10.0) }}
  accumulate_gradients: {{ ubuntu_oasentinel.accumulate_gradients | default(1) }}
  
  # Model optimization
  compile_model: {{ ubuntu_oasentinel.compile_model | default(false) }}  # PyTorch 2.0 compile
  channels_last: {{ ubuntu_oasentinel.channels_last | default(false) }}  # Memory format optimization