# Ubuntu GPU Training Configuration for oaSentinel
# Generated by Ansible oaAnsible/roles/ubuntu/ml_workstation
# Optimized for {{ gpu_type if gpu_type is defined else 'NVIDIA GPU' }} on Ubuntu {{ ansible_distribution_version }}

# Model configuration
model_name: "yolo11n.pt"
model_size: "n"  # Start with nano, can scale up
input_size: 640

# Dataset configuration
dataset_name: "crowdhuman"
num_classes: 1
class_names: ["person"]

# Training parameters optimized for GPU server
epochs: 100
{% if gpu_type is defined and 'RTX 3080' in gpu_type %}
batch_size: 32  # RTX 3080 Ti can handle larger batches
{% elif ansible_memtotal_mb|int >= 16384 %}
batch_size: 24  # High memory system
{% else %}
batch_size: 16  # Conservative for lower memory
{% endif %}
learning_rate: 0.001
patience: 15
save_period: 10

# GPU-specific optimizations
device: "cuda"  # Use CUDA for GPU acceleration
workers: {{ [ansible_processor_vcpus|int, 12]|min }}  # Optimize workers for CPU cores
half_precision: true  # Enable FP16 for better GPU performance

# Optimization settings for GPU training
optimizer: "AdamW"  # Performs well on GPUs
lr_scheduler: "cosine"
warmup_epochs: 5
weight_decay: 0.0005
momentum: 0.937

# Data augmentation for robust training
augment: true
mixup: true  # Enable for better generalization
copy_paste: false  # Disable for faster training

# Output settings
project_name: "oaSentinel-GPU"
experiment_name: "{{ inventory_hostname }}-{{ gpu_type|replace(' ', '-')|lower if gpu_type is defined else 'gpu' }}-training"

# Validation settings
val_split: 0.2
test_split: 0.1

# Advanced GPU settings
freeze: null  # Don't freeze layers initially
pretrained: true  # Use pretrained weights

# Export settings for deployment
export_formats: ["coreml", "onnx"]
optimize: true

# Logging and monitoring
verbose: true
plots: true
save_json: true
save_hybrid: false

# GPU-specific notes
# - Optimized for high-performance GPU training
# - Uses mixed precision (FP16) for memory efficiency
# - Configured for {{ gpu_type if gpu_type is defined else 'NVIDIA GPU' }}
# - Monitor GPU usage with: gpu-watch
# - Training logs: tail -f logs/training/*.log