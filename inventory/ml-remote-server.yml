---
# ML Remote Training Server Inventory
# For setting up oaSentinel training on kampus-rig (RTX 3080 Ti server)

all:
  children:
    ubuntu:
      hosts:
        kampus-rig:
          ansible_host: kampus-rig
          ansible_user: kai
          ansible_ssh_private_key_file: ~/.ssh/id_rsa
          
          # Hardware specifications
          gpu_count: 1
          gpu_type: "RTX 3080 Ti"
          total_memory_gb: 31
          available_storage_gb: 430
          
      vars:
        # Platform identification
        ansible_distribution: Ubuntu
        ansible_distribution_version: "24.04"
        
        # Server configuration
        is_gpu_server: true
        enable_remote_access: true
        
        # Role execution control
        execute_base_setup: true
        execute_nvidia_setup: true
        execute_docker_setup: true
        execute_ml_setup: true
        execute_monitoring_setup: true
        
        # oaSentinel specific settings
        oasentinel_repo_branch: main
        python_version: "3.11"  # We'll use 3.11 for compatibility with existing oaSentinel
        
        # NVIDIA/CUDA Configuration
        nvidia_config:
          install_drivers: true
          install_cuda: true
          install_cudnn: true
          cuda_version: "12.1"
          driver_version: "latest"
        
        # Ubuntu ML optimization for high-end server
        ubuntu_ml_optimization:
          increase_shared_memory: true
          optimize_swap: true
          increase_file_limits: true
          install_build_essentials: true
          enable_performance_governor: true
        
        # Training server features
        training_server:
          enable_jupyter: true
          jupyter_port: 8888
          enable_tensorboard: true
          tensorboard_port: 6006
          setup_screen_sessions: true
        
        # Data management optimized for large datasets
        data_management:
          create_datasets_dir: true
          datasets_path: "/data/ml-datasets"
          optimize_io: true
        
        # Docker ML configuration with GPU support
        docker_ml_config:
          install_nvidia_runtime: true
          enable_gpu_support: true
        
        # Training configuration optimized for RTX 3080 Ti
        training_config:
          default_epochs: 100
          default_batch_size: 32  # RTX 3080 Ti can handle higher batch sizes
          auto_device_detection: true
          mixed_precision: true
        
        # ML frameworks with GPU focus
        ml_frameworks:
          pytorch: true
          ultralytics: true
          opencv: true
          jupyter: true
          wandb: true  # Enable for professional training tracking
        
        # Performance optimization for training server
        performance_optimization:
          enable_gpu_monitoring: true
          optimize_memory: true
          enable_profiling: true
        
        # Remote access settings for development
        remote_access:
          monitoring_dashboard: true
          setup_reverse_tunnel: false
          
        # Development tools enabled
        dev_tools:
          enable_jupyter: true
          enable_tensorboard: true
          enable_code_formatting: true
          enable_testing: true