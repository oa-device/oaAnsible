# oaSentinel Environment Configuration
# Generated by Ansible for {{ inventory_hostname }}

# Project Configuration
OASENTINEL_HOME={{ oasentinel_dir }}
PYTHONPATH={{ oasentinel_dir }}/src:$PYTHONPATH

# GPU Configuration
{% if ml_has_nvidia_gpu is defined and ml_has_nvidia_gpu %}
CUDA_VISIBLE_DEVICES={{ oasentinel.cuda_devices | default('0') }}
CUDA_LAUNCH_BLOCKING={{ oasentinel.cuda_debug | default('0') }}
{% endif %}

# Training Configuration
WANDB_PROJECT={{ oasentinel.wandb_project | default('oaSentinel') }}
WANDB_MODE={{ oasentinel.wandb_mode | default('disabled') }}
{% if oasentinel.wandb_api_key is defined %}
WANDB_API_KEY={{ oasentinel.wandb_api_key }}
{% endif %}
{% if oasentinel.wandb_entity is defined %}
WANDB_ENTITY={{ oasentinel.wandb_entity }}
{% endif %}

# Hugging Face Configuration (for dataset downloads)
{% if oasentinel.hf_token is defined %}
HF_TOKEN={{ oasentinel.hf_token }}
HUGGINGFACE_HUB_TOKEN={{ oasentinel.hf_token }}
{% endif %}

# PyTorch Configuration
TORCH_HOME={{ oasentinel_dir }}/models/torch_cache
TORCH_CUDA_ARCH_LIST="{{ oasentinel.cuda_arch_list | default('7.0;7.5;8.0;8.6') }}"

# Training Optimization
TOKENIZERS_PARALLELISM={{ oasentinel.tokenizers_parallel | default('false') }}
OMP_NUM_THREADS={{ ansible_processor_vcpus | default(4) }}
MKL_NUM_THREADS={{ ansible_processor_vcpus | default(4) }}

# System Configuration
TMPDIR={{ oasentinel.temp_dir | default('/tmp') }}
CUDA_CACHE_PATH={{ oasentinel_dir }}/cache/cuda

# Logging Configuration
PYTHONUNBUFFERED=1
TQDM_DISABLE={{ oasentinel.disable_tqdm | default('0') }}

# Development Configuration
OASENTINEL_ENV={{ oasentinel.environment | default('production') }}
OASENTINEL_DEBUG={{ oasentinel.debug | default('0') }}
OASENTINEL_LOG_LEVEL={{ oasentinel.log_level | default('INFO') }}